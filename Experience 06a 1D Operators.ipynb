{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6a: 1D Operator formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's integrate our operator knowledge, exploring how to create simple operators for the 1D problems that we analyzes in the past. Let's start from the continuity equation, in 1D. This is extremely straightforward because $\\nabla \\cdot \\mathbf{v} = 0$ becomes $\\frac{\\partial v_x}{\\partial x}=0$. Let's therefore create the derivative operator in 1D.\n",
    "\n",
    "We already discovered in the previous experiences that derivatives can be done forward, backward or centered. Let's recall here what we did in the Experience 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "tmax = 2.0 #ending time in seconds\n",
    "tmin = 0.0 #starting time \n",
    "intervals = 20 #number of divisins on time interval\n",
    "dt =(tmax-tmin) / intervals #time stepping\n",
    "nt = intervals + 1\n",
    "time = np.arange(nt) * dt\n",
    "\n",
    "x=np.zeros(nt) #setting Initial position to zero\n",
    "\n",
    "x[0:nt]=np.sin(2*np.pi*time[0:nt])\n",
    "test= np.arange(1001)* (tmax-tmin) / 1000\n",
    "\n",
    "plt.plot(test,np.sin(2*np.pi*test),'-',alpha=0.1)\n",
    "plt.plot(time,x,'o');\n",
    "plt.show()\n",
    "\n",
    "dxdtForward = np.zeros(nt)\n",
    "dxdtBackward = np.zeros(nt)\n",
    "dxdtCentered = np.zeros(nt)\n",
    "\n",
    "dxdtForward[0:nt-1] = (x[1:nt]-x[0:nt-1])/dt\n",
    "dxdtBackward[1:nt] = (x[1:nt]-x[0:nt-1])/dt\n",
    "dxdtCentered[1:nt-1] = 0.5 * (dxdtForward[1:nt-1] + dxdtBackward[1:nt-1])\n",
    "dxdtCentered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly for an oscillatory motion the continuity equation is not conserved. And that is normal, because in 1D the analytical solution of the continuity equation is very boring. Just an media traveling ad constant speed towards right or left. So, let's forget about the continuity equation and let's focus on how we could have calculated the derivative with an operator, a tensor, instead of the numpy call above. We have to find a matrix such that:\n",
    "\n",
    "\\begin{align}\n",
    "A_{ij} \\cdot x_i = \\left(\\frac{dx}{dt}\\right)_j\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the indexes indicate the point in space where you are calcualting your derivative. Let's first create together the matrix equivalent to dxdtForward:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we create a matrix of the right size of zeros:\n",
    "block=np.zeros((nt,nt),float)\n",
    "\n",
    "# now we start exploring special numpy functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identity:\n",
    "A=np.identity(nt)\n",
    "print('identity')\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diag()\n",
    "A=np.diag(np.ones(nt)*2)\n",
    "print('diag')\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shifted diag()\n",
    "A=np.diag(np.ones(nt)*3,2)\n",
    "print('shifted diag')\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kron()\n",
    "print(np.ones((3,3)))\n",
    "print('times')\n",
    "print(np.identity(3)*4)\n",
    "print('makes')\n",
    "A=np.kron(np.ones((3,3)),np.identity(3)*4)\n",
    "print(A)\n",
    "print('kron is a controlled combination of matrices')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since dxdtForwardOp is simply 1/dt for the difference between the next and the present value of x, then it is made of two diagonals next to each other, one to the right and the other on the main diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dxdtForwardOp = -1/dt*np.diag(np.ones(nt)) + 1/dt*np.diag(np.ones(nt-1),1)\n",
    "print(dxdtForwardOp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see if it works!\n",
    "dxdtForward[0:nt-1] = (x[1:nt]-x[0:nt-1])/dt\n",
    "dxdtForward2 = np.zeros(nt)\n",
    "dxdtForward2= dxdtForwardOp.dot(x)\n",
    "\n",
    "plt.plot(time,dxdtForward,'+');\n",
    "plt.plot(time,dxdtForward,'x');\n",
    "plt.show()\n",
    "\n",
    "print(dxdtForward-dxdtForward2)\n",
    "# PERFECT!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more careful look at what we created should highlight that the solution was not perfect. One point is miscalculated. The last one. This is normal, because we need the next number to calculate the derivative. So, out of nt values for x, we can calculate only nt-1 values of the derivative, using this first order approximation. But that is ok. Just we understand that the operator should go from nt to nt-1, so it should not be a squared matrix but a rectangular one, with dimensions $nt * (nt-1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "Create the other two matrix operators, the backward and centered ones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here write your solution\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now calculate the second derivative. We remember the nicely centerd formulation from the kinematic experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2xdt2 = ( x[0:nt-2] - 2*x[1:nt-1] + x[2:nt] ) / dt**2\n",
    "plt.plot(time[1:-1],d2xdt2,'o');\n",
    "#where you see that now it has dimensions nt-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "Create directly this operator, d2xdt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write here your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do now something more interesting. Let's create the second operator by multiplying the operator derivative in one 1D by itself. Clearly, we need to be careful to the dimensions (reduction of one for each derivative). Other than that, we just have to repeat the work twice. Let's what happens if I use only the centered version of the 1D operators.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first I create the centered operator like before\n",
    "dxdtCenteredOp = -1/2/dt*np.diag(np.ones(nt-1),-1) + 1/2/dt*np.diag(np.ones(nt-1),1)\n",
    "# and then a multiply it by itself:\n",
    "d2xdt2OpCentered = dxdtCenteredOp.dot(dxdtCenteredOp)\n",
    "print(d2xdt2OpCentered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is different from the operator that we just created directly. How can this be??\n",
    "\n",
    "Do you remember when introducing these derivatives in kinematics, we said that this kind of operator is dispersive. Too dispersive! In fact, although the results look similar (try it!) it is not the same, and smooths the function a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare here the two results, with the operator that we built directly \n",
    "#and with the operator from the product of the two\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, how do we create the correct (best!) operator? The trick is to use the forward and the backward. Which seems a paradox because each one was less correct than the centered one. But the poins is that they were biased, but not dispersive, and the two biases disappear when multypling one with the other! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "Create now the operator d2xdt2, by multypling either the forward and the backward or the backward and the forward. Does the result change? And compare how it operates with the best estiamate \n",
    "d2xdt2 = ( x[0:nt-2] - 2*x[1:nt-1] + x[2:nt] ) / dt**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here write your solution\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse operators\n",
    "\n",
    "Let's address now a last problem, which is actually of minor importance in 1D but fundamental in 2D. Sparse and dense operators. The problem is simply that the matrix above, is almost entire made by zeros. So, we are filling up the memory of our computers of zeros. What a waste of memory! And what a waste of computing time at multypling all these zeros for x or for other zeros (when multypling one operator for another). \n",
    "\n",
    "Computer scientists figured out long time ago that there had to be a better way. They invented therefore sparse matrices. They can be easily studies from scipy or numpy sparse. But quickly said here, sparse matrices are written in the computer not as the list of values, but as the list of non-zero values, as (i,j,value) where i and j are the coordinates of the non-zero value. \n",
    "\n",
    "Of the many sparse arrays that exist in Python, the CSR format (Compressed Sparse Column format) is specially suitable for fast matrix vector products. Since all our matrix come from some combinations of diagonal matrices, we can combine them into a CSR format. Let's see an example for the matrices that we created earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start from a diagonal sparse matrix:  \n",
    "a=sparse.dia_matrix((np.ones(nt)*3,0), shape=(nt,nt) ).tocsr()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the zero is the offset. Let's play with it a bit:\n",
    "a=sparse.dia_matrix((np.ones(nt)*5,5), shape=(nt,nt) ).tocsr()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can see that the representation is not the one of before. \n",
    "# what if we want to visualize it as a normal matrix? We can always change into a standard matrix and plot it.\n",
    "a2=a.toarray()\n",
    "plt.imshow(a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# products are just the same:\n",
    "y=a.dot(x)\n",
    "y2=a2.dot(x)\n",
    "print(y)\n",
    "print(y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Create now the operators dxdtcentered and dxdt2 using sparse matrices. You can also try to use the matrix product (using backward and forward) to build the second derivative. Check that the solution is correct either by comparing the matrix with .toarray or mulutplying it for a test x vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write here your solution\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
