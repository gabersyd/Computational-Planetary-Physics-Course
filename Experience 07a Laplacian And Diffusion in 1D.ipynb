{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experience 07a: Diffusion and Laplacian Operator in 1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diffusion of taste is not the same thing as the improvement of taste.\n",
    "William Hazlitt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important physical process in Geodynamics is probably the second law of thermodynamics that says that the disorder in the universe constantly grows. In fact physics tells us that the second law is the main indication of what is time, given that the growth of entropy is the only non-reversible process among the fundamental laws of physics. \n",
    "\n",
    "Among the geodynamic processes the growth of the entropy manifests itself mainly by diffusional processes. Diffusion is in fact a throughly irreversible processes, characterized by the chaotic mix of particles of different nature, like the diffusion of a drop of color in water, or by the flow of heat from a hot to a cold body, or by the diffusion of a liquid in a porous media (Darcy's flow). All these phenomena happen in any long term process, making diffusion an ubiquitous actor in geodynamics. \n",
    "\n",
    "Historically the similarity between diffusion of a fluid into another fluid and the diffusion of heat in a solid convinced scientists that heat was nothing else than a invisible fluid, called *calorico* that was transporting this energy, heat. Maxwell and Boltzmann were the pioneers who figured out first the equivalence between heat and kinetic energy, and that therefore the temperature was nothing else than the measure of the kinetic energy of every single mode of motion of particles. For example for a monoatomic Noble gas the average kinetic $\\frac{1}{2} m v^2$ of each atom is $\\frac{3}{2}kT$ where k is the Boltzmann constant ($1.38 \\cdot  10^{23} \\; J/K$) and m is the mass of the atom. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory of the Diffusion Processes\n",
    "\n",
    "In geodynamics we mostly deal with crystalline rocks for which the heat is stored as the kinetic energy of vibrating atoms whose position oscillates around the equilibrium position in the lattice. This kinetic energy is transmitted to the neighboring atoms through inter-atomic electric forces. Also here the kinetic energy associated to the atomic oscillation is $\\frac{3}{2}kT$. The fact that all these different phenomena are controlled by the same laws is at the same time a truly remarkable aspect of physics and also greatly simplifies the life of geodynamic modelers because it makes the numerical modeling of these effects very similar. \n",
    "\n",
    "For example after their formation at mid ocean ridges, crust and lithosphere cool mostly due to diffusion of heat at the surface, while the plates slide horizontally for 100 million years or more. Heat diffusion also balances the convection in the mantle and reduces its intensity. Chemical diffusion in planetary interiors can be very complex because several materials diffuse a different speed, creating nonlinear effects, that however ultimately reduce to the same general law. In general every material that we as humans will try to constrain to protect the environment (e.g. radioactive, pollution) will ultimately leak out. For example stocking $CO_2$ in rocks is limited by the efficiency of the diffusion in rock, as well as the storage of geothermal heat at the surface. We cannot stop these processes, but we can monitor and limit them.\n",
    "\n",
    "Another type of phenomena that surprisingly follows the diffusion law is random walk. It was Einstein who understood first that the seemingly chaotic motion of a large particle immersed in a fluid, also called Brownian motion, can be described by their being hit by vibrating molecules. By calculating the overall effect of these collisions he devised a way to calculate the effective diffusion of these particles and the effective viscosity of the fluid, only from the Avogadro number N of particles in a mole and from the size of the molecules. This calculation concluded his PhD thesis, demonstrated the existence of atoms, showed how their large scale effect is a diffusional process and was the discovery for which he was awarded the Nobel price in physics in 1921. \n",
    "\n",
    "Similarly to random walk, the diffusion of the single parcels of fluid in porous rocks follows complex pattern that overall average to a diffusion process. Hydrogeological flow and geothermal flows are driven diffusion processes that acquire a direction because of the gravity forcing. In the last part of the book I will discuss the microscopic aspects of this multicomponent and multiphase flow and their modeling. \n",
    "\n",
    "Since all forms of diffusion follow the same law, I will discuss here how to solve the heat equation, without loosing generality. This can be generalized to any other diffusion process. Regardless on which phenomena it refers to, ultimately diffusion is described by a \\emph{coefficient of diffusion} that can depend on any macroscopic variable. For heat diffusion with thermal conductivity $k$, density $\\rho$ and heat capacity at constant pressure $C_p$ the thermal diffusivity is defined as $\\kappa = k / (\\rho C_p)$. Let's see how to prove this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If diffusion is the only thermal process, mathematically the evolution of temperature in a cell depends only on the difference between the heat that is coming and the one that is leaving the cell. In one dimension this can be simply expressed by calculating the heat flux $q$ as:\n",
    "\n",
    "\\begin{equation}\n",
    "q_x= - k \\frac{\\partial T}{\\partial x}\n",
    "\\end{equation}\n",
    "\n",
    "where $k$ is the thermal conductivity and the mines indicates that the heat goes from the region of higher to lower temperatures. The temperature change in cell of material that is sufficiently small that we can consider temperature constant and for a time  is:\n",
    "\n",
    "\\begin{equation}\n",
    "\tC_p \\rho \\delta T = \\frac{\\partial q_x}{\\partial x} \\delta t \n",
    "\\end{equation} \n",
    "\n",
    "where the derivative of $q_x$ indicates the differential heat flow. By dividing by $\\delta t$ one obtains:\n",
    "\n",
    "\\begin{equation}\n",
    "C_p \\rho \\frac{\\partial T}{\\partial t} = - \\frac{\\partial }{\\partial x}\\left(k \\frac{\\partial T}{\\partial x} \\right)\n",
    "\\end{equation} \n",
    "\n",
    "where in the left side term the temperature $T=T(x,t)$ that is both a function of space and time is derived \\emph{partially} by the time, where the partial derivatives means that the cell does not move. This way to average quantities is called Eulerian. It is the point of view of an observer that does not move with the fluid. \n",
    "\n",
    "If $C_p$ and $\\rho$ are constant we can express thise equation in function of a unique parameter and naturally extended them in 2D and 3D:\n",
    "\n",
    "\\begin{align}\n",
    "\\label{diffusion-equation-1d-2d-3d}\n",
    "\\frac{\\partial T \\left(x,t\\right)}{\\partial t} &= \\frac{\\partial }{\\partial x}\\left(k \\frac{\\partial T}{\\partial x} \\right)\\\\\n",
    "\\frac{\\partial T \\left(x,y, t\\right)}{\\partial t} &= \\frac{\\partial }{\\partial x} \\left(k \\frac{\\partial T}{\\partial x} \\right) + \\frac{\\partial }{\\partial y} \\left( k \\frac{\\partial T}{\\partial y}\\right)\\nonumber\\\\\n",
    "\\frac{\\partial T \\left(x,y,z, t\\right)}{\\partial t} &= \\frac{\\partial }{\\partial x} \\left(k \\frac{\\partial T}{\\partial x} \\right) + \\frac{\\partial }{\\partial y} \\left( k \\frac{\\partial T}{\\partial y}\\right) + \\frac{\\partial }{\\partial z} \\left( k \\frac{\\partial T}{\\partial z}\\right)\\nonumber\n",
    "\\end{align}\n",
    "\n",
    "Here x, y, z and t indicate the \\emph{independent} variables. One of the most important characteristics of these equations are the presence of the diffusivity inside the parenthesis. If the diffusivity is constant respect to space, we could extract it from the derivative and these equation would immediately simplify into:\n",
    "\n",
    "\\begin{align}\n",
    "\\label{diffusion-constant-diffusivity}\n",
    "\\frac{\\partial T \\left(x,t\\right)}{\\partial t} &= k \\frac{\\partial^2 T}{\\partial x^2}\\\\\n",
    "\\frac{\\partial T \\left(x,y, t\\right)}{\\partial t} &= k \\left( \\frac{\\partial^2 T}{\\partial x^2 } + \\frac{\\partial^2 T}{\\partial x^2 } \\right) \\nonumber \\\\\n",
    "\\frac{\\partial T \\left(x,y,z, t\\right)}{\\partial t} &= k \\left( \\frac{\\partial^2 T}{\\partial x^2} + \\frac{\\partial^2 T}{\\partial x^2 } + \\frac{\\partial^2 T}{\\partial x^2 } \\right) \\nonumber\n",
    "\\end{align}\n",
    "  \n",
    "However the most general case, and also the most interesting from the geodynamic point of view, is the one in which $k$ is non-homogenous, and possibly non-linear depending on some physical parameters.\n",
    "\n",
    "We can already envisage here how the operators introduced earlier can be applied here. If the diffusivity is in the parenthesis we can simply first create a derivative operator, then apply the diffusivity, then apply the derivative operator again and so obtain the temperature increment in time. This simple approach, called \\emph{explicit}, is however effective only for very small time-steps, as we will see in another chapter. \n",
    "\n",
    "We have considered above only the flow of heat. In general both heat and material can flow, and the material will transport heat with it, creating what is called \\emph{advection} of heat. This case is a simple extension of the one above, where we can replace replace the \\emph{partial} derivative in the terms on the left with a \\emph{full} derivative, using the standard definition of derivatives. In 1D, for example, it looks like: \n",
    "\n",
    "\\begin{equation}\n",
    "\\label{Lagrangian-definition}\n",
    "\\frac{d T(x,t)}{dt} = \\frac{\\partial T}{\\partial t} + \\frac{\\partial T}{\\partial x}\\frac{\\partial x}{\\partial t} = \\frac{\\partial T}{\\partial t} + v_x\\frac{\\partial T}{\\partial x}\n",
    "\\end{equation}\n",
    "\n",
    "where $v_x$ is the $x$ component of the velocity vector. The extension in 2D and 3D is obvious. This way to calculate a derivative is called \\emph{Lagrangian}, in opposition to the \\emph{Eulerian} viewpoint introduced earlier. In practice the Eulerian viewpoint means that I stay on the side of a river and look at water flowing and bringing everything with it. The Lagrangian viewpoint is equivalent to be on a canoe without paddles and letting the stream taking me with it. By combining equations and taking the velocity bearing terms to the right hand side one obtains:\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial T \\left(x,t\\right)}{\\partial t} &= \\frac{\\partial }{\\partial x}\\left(k \\frac{\\partial T}{\\partial x} \\right) - v_x\\frac{\\partial T}{\\partial x} \\nonumber \\\\\n",
    "\\frac{\\partial T \\left(x,y, t\\right)}{\\partial t} &= \\frac{\\partial }{\\partial x} \\left(k \\frac{\\partial T}{\\partial x} \\right) + \\frac{\\partial }{\\partial y} \\left( k \\frac{\\partial T}{\\partial y}\\right) - v_x\\frac{\\partial T}{\\partial x} - v_y\\frac{\\partial T}{\\partial y} \\nonumber \\\\\n",
    "\\frac{\\partial T \\left(x,y,z, t\\right)}{\\partial t} &= \\frac{\\partial }{\\partial x} \\left(k \\frac{\\partial T}{\\partial x} \\right) + \\frac{\\partial }{\\partial y} \\left( k \\frac{\\partial T}{\\partial y}\\right) + \\frac{\\partial }{\\partial z} \\left( k \\frac{\\partial T}{\\partial z}\\right) - v_x\\frac{\\partial T}{\\partial x} - v_y\\frac{\\partial T}{\\partial y} - v_z\\frac{\\partial T}{\\partial z} \\nonumber \n",
    "\\end{align*}\n",
    "\n",
    "Again we can envisage just by looking at this formulation how we can use the operator format to calculate the right hand side, comprised of the advection terms, and then use it to calculate the Temperature increment. Although is this technique intrinsically unstable, its implementation is a very interesting and useful exercise, whose limitations stimulate at learning and understanding the more challenging implicit techniques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicit Diffusion Implementation\n",
    "\n",
    "Explicit numerical formulation are the easiest to implement and when effective, extremely useful. Unfortunately a **stability** issue is common to most of them, and it is important to understand from the beginning what causes them.\n",
    "\n",
    "To familiarize with the problem of stability it is easier to look at the simplest equation, the 1D version of the non advecting heat flow equation with constant coefficients. We can immediately extend the first derivative in time and the second derivative in space as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{ T^{t+\\Delta t} \\left( x_i \\right) - T^t \\left( x_i \\right) } {\\Delta t} = k \\frac{T^t \\left( x_{i+1} \\right) -2T^t \\left( x_i \\right) + T^t \\left(x_{i-1} \\right)}{\\Delta x ^2} \n",
    "\\label{eq-diff-1D}\n",
    "\\end{equation}\n",
    "\n",
    "If the space discretization is constant, it is possible to reformulate the temperature at the time $t+\\Delta t$ in function of the temperature at the time $t$ and of a unique parameter $r=k \\Delta t / \\Delta x^2$:\n",
    "\n",
    "\\begin{equation}\n",
    "T^{t+\\Delta t} = T^t \\left( x_i \\right) + r * \\left[ T^t \\left( x_{i+1} \\right) -2T^t \\left( x_i \\right) + T^t \\left(x_{i-1} \\right) \\right]\n",
    "\\label{eq-diff-expl-1D}\n",
    "\\end{equation}\n",
    "\n",
    "Let's now use the techniques that we learned in the past chapters to create a straightforward implementation of this formula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nxp=101; nxc=nxp-1; xTot=1.0; \n",
    "dx=xTot/nxc; xMin=-xTot/2.0; xMax=xTot/2.0\n",
    "steps=1000; totalTime=1.0; plotEverySteps = 100; \n",
    "deltaTime=totalTime/steps\n",
    "diffusivity=1e-1; r = deltaTime*diffusivity/(dx*dx)\n",
    "\n",
    "X = np.arange(nxp)*dx+xMin\n",
    "T = np.sin(2*np.pi*X)\n",
    "\n",
    "print('r=',r)\n",
    "DT=np.zeros(nxp)\n",
    "for time in np.arange(35):\n",
    "    DT[1:nxp-1]=T[0:nxp-2]-2*T[1:nxp-1]+T[2:nxp]\n",
    "    T += r * DT\n",
    "    print(time,np.max(T));\n",
    "    plt.plot(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "Start from the above program and change r until you reach stability. What is the critical value from stability to instability? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here write your solution\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where $X$ is space, $T$ is the temperature, and the system is initialized with a smooth sinusoidal initial temperature. The system is explicit in the sense that the Laplacian of the temperature field, used to calculated the Temperature increment, is calculated at the old time-step and then used to calculate the new temperature field. \n",
    "\n",
    "By playing with any parameter that changes the coefficient $r$, one discovers that regardless on the quality of the result (that can be very with with many short time-steps), as soon as the coefficient $r$ is above the value $0.5$, the system becomes completely unstable. \n",
    "\n",
    "This is a typical example of counterintuitive aspects of Numerical modeling. Why does this instability appear? What happens is that for $r>05$ small perturbations amplify exponentially. This can be understood from the line $T += r * DT$. Given that $DT$ for certain part of the function $T$ becomes two times the difference between the temperature in one point and its neighboring one, when $r$ is greater than $0.5$ then $r*DT$ becomes greater than this difference and therefore at the next time-step the difference between the temperature at one node and the temperature of the next node becomes greater, triggering this instability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicit formulation using operators\n",
    "\n",
    "Before discussing about how the stability problem can be solved, let's look at how we can use the operators that we introduced in the past experience to obtain the same result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "Start from the operator that we introduced in the previous experiences and use it check the same transition from stable to unstable explicit diffusion. Is the use of the operator faster or slower than the above implementation? Use %timeit to quantify it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here you can write your solution\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where the Laplacian only updates the internal values of the nodes of the Temperature. In a real scenario the external temperature nodes could be set to values that depend on Boundary conditions. This sophisticated approach does not solve stability, but these operators will turn to be very useful for developing implicit formulations. The reader is however invited to test this formulation to empirically find the critical $r$. \n",
    "\n",
    "It is clear here that since instabilities arise for very small time-steps, it would be desirable to use another incremental procedure for the diffusion equation. However it is important to keep in mind that explicit solver are really extremely fast and for small time-steps produce accurate solutions, therefore when other complications in the numerical model such as severe nonlinearities in the solution of the momentum equation limit time steps below critical stability, the use of explicitly temperature diffusion is still commonly used. Clearly in this case it is essential to check at every time-step that the critical $\\Delta t$ is never reached. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implicit Formulation\n",
    "\n",
    "The way to overcome the limitations of the explicit formulation is to embed the future solution into the calculation of the temperature (or other field) diffusion increment. This approach requires in some way to invert the **Laplacian** operator that we introduced previously. This more computationally demanding approach has however the ability to offer more accurate solutions and in particular it is unconditionally stable for any $\\Delta t$.\n",
    "\n",
    "If we rewrite the 1D discretization of the diffusion equation changing the right hand side and calculating it on the final time-step instead of the initial one the equation appears as follow:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{ T^{t+\\Delta t} \\left( x_i \\right) - T^t \\left( x_i \\right) } {\\Delta t} = k \\frac{T^{t+\\Delta t} \\left( x_{i+1} \\right) -2T^{t+\\Delta t} \\left( x_i \\right) + T^{t+\\Delta t} \\left(x_{i-1} \\right)}{\\Delta x ^2} \n",
    "\\label{eq-diff-impl-1D}\n",
    "\\end{equation}\n",
    "\n",
    "Now, following the same procedure of \\sect{sec-diff-expl} we rewrite the new values of the field T in function of the old one as well as of the new one:\n",
    "\n",
    "\\begin{equation}\n",
    "T^{t+\\Delta t} \\left( x_{i} \\right) = T^t \\left( x_i \\right) + r * \\left[ T^{t+\\Delta t} \\left( x_{i+1} \\right) -2T^{t+\\Delta t} \\left( x_i \\right) + T^{t+\\Delta t} \\left(x_{i-1} \\right) \\right]\n",
    "\\label{eq-diff-impl-1D-2}\n",
    "\\end{equation}\n",
    "\n",
    "where again $r=k \\Delta t / \\Delta x^2$. Contrary to the explicit formulation, the new values of the field T depend on the old and on the new values themselves. As we see in the following this inhibits the instabilities that we saw before to arise. \n",
    "\n",
    "To solve the above equation we need to group all the terms containing $t+\\Delta t$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\left( 1+2r \\right) T^{t+\\Delta t} \\left( x_{i} \\right) -r T^{t+\\Delta t} \\left( x_{i+1} \\right) -r T^{t+\\Delta t} \\left(x_{i-1} \\right)  = T^t \\left( x_i \\right)\n",
    "\\label{eq-diff-impl-1D-3}\n",
    "\\end{equation}\n",
    "\n",
    "Since the terms at the next time-step are unknown, this equation cannot be written as a simple increment to the old time-step, but it requires the solution of N coupled linear equations, representing the new temperature vector as an evolution of the old temperature field. This has an operator formulation. \n",
    "\n",
    "Calling $\\mathbf{T}^t$ the  vector of all solutions at the time $t$, the above equation can be written in a compact form at ever point as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathsf{(I+A)} \\mathbf{T}^{t+\\Delta t} = \\mathbf{T}^{t}\n",
    "\\end{equation}\n",
    "\n",
    "where $I$ is the identity matrix, $\\mathsf{A}$ represents the evolutionary tridiagonal matrix characterized by $2r$ on the diagonal and $-r$ on the sides of the diagonal, while all the other components of $\\mathsf{A}$ are zero. \n",
    "\n",
    "The above system can be solved just by finding the inverse matrix $\\mathsf{B}=\\mathsf{(I+A)}^{-1}$. A matrix is always invertible if the determinant is non-zero (because the determinant is equal to the product of all the eigenvalues, and if no-eigenvalue is zero it can be inverted), which is our case for every non-zero value of $r$. This implies that there is a stable solution for every time-step, although a larger time-step will be less correct. We have so a straightforward expression to use in Python to find the next temperature distribution, given the old one:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{T}^{t+\\Delta t} = \\mathsf{(I+A)^{-1}} \\mathbf{T}^{t} = \\mathsf{B} \\mathbf{T}^{t}\n",
    "\\end{equation}\n",
    "\n",
    "For simplification I will create a function that generates the  tridiagonal matrix that I have introduced above by using the feature of the **diag** function in NumPy and in sparse, for comparison. One might wonder why not creating immediately only a sparse matrix and work only with them. The problem is that, as we will see, the inverse of a sparse matrix is not always sparse and if a matrix is dense it is more efficient to treat it as a normal NumPy array. Let's start with a dense matrix:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def tridiagDense(r, nxp, k1=-1, k2=0, k3=1):\n",
    "    a = np.ones(nxp-1)*(-r)\n",
    "    b = np.ones(nxp)*(2.*r)\n",
    "    return np.diag(a, k1) + np.diag(b, k2) + np.diag(a, k3)\n",
    "\n",
    "nxp=101; nxc=nxp-1; xTot=1.0; dx=xTot/nxc; xMin=-xTot/2.0; xMax=xTot/2.0\n",
    "steps=100; totalTime=1.0; plotEverySteps = 1; deltaTime=totalTime/steps\n",
    "diffusivity=1e-1; r = deltaTime*diffusivity/(dx*dx); print('r:',r) \n",
    "\n",
    "IA = np.identity(nxp)+tridiagDense(r,nxp) # I+A\n",
    "B = np.linalg.inv(IA) # inverse dense matrix\n",
    "\n",
    "# initialization\n",
    "X = np.arange(nxp)*dx+xMin \n",
    "T = np.sin(2*np.pi*X)\n",
    "\n",
    "for time in np.arange(steps):\n",
    "    T = B.dot(T)  #temperature at t + deltaTime\n",
    "    plt.plot(T)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3  \n",
    "Change the value of r and make it small or large and verify that the solver is unconditionally stable. However verify also for which $r$ is the quality of the solution not accepptable anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here write your solution\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach returns immediately the same correct solution of the explicit approach, but now we are not limited anymore to small values of $r$. One can in fact obtain the same solution that required $1000$ steps with the explicit approach, in only $10$ steps with the implicit approach. This implies that not only is the implicit approach stable, but it is also very accurate. \n",
    "\n",
    "The reason for the extraordinary accuracy is largely due to the structure of the inverse matrix. This is not a sparse matrix like the explicit ones. The lack of sparsity increases with $r$, and therefore with its ability to propagate the present solution in the future. Let's visualize the matrices $IA$ and $B$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(IA);plt.colorbar();plt.show()\n",
    "plt.imshow(B);plt.colorbar();plt.show()\n",
    "\n",
    "plt.plot(IA[nxp//2]/IA.max())\n",
    "plt.plot(B[nxp//2]/B.max())\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lack of sparsity of the inverse matrix is important for large problems. The size of the matrix that we have to invert scales like the square of the number of points. So on a normal computer if we have $10000$ points we will have a matrix with $100$ millions of entries, which is already close to its memory limits. And this is only equivalent to a $100 \\times 100$ 2D problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "Plot the matrix and in particular the central section of the matrices IA and B changing r. Do the values far from zero increase, decrease or remain the same when r increases? What are the implications for turning this matrix into a sparse matrix? For example, if you assign to zero the values that are close to zero, will the result change? Try!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here write your solution\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of sparse libraries for calculating the matrix inverse is not helpful either. For example we could have defined the tridiagonal matrix as a sparse one with the function $tridiagSparse$, then inverting it with the sparse libraries of scipy. This would have been written for example as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sparse\n",
    "import scipy.sparse.linalg as la\n",
    "\n",
    "def tridiagSparse(r, nxp, k1=-1, k2=0, k3=1):\n",
    "    a = np.ones(nxp)*(-r)\n",
    "    b = np.ones(nxp)*(2.*r)\n",
    "    return sparse.dia_matrix(([a,b,a],[k1,k2,k3]),shape=(nxp,nxp)).tocsc()\n",
    "    \n",
    "IA = sparse.eye(nxp).tocsc()+tridiagSparse(r,nxp)\n",
    "B = la.inv(IA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However this does not bring any substantial advantage. A test of the two approaches shows that the sparse matrix approach is about twice as slow as the dense one for $nxp=1000$, regardless to the value of $r$. \n",
    "\n",
    "**The generally agreed solution for solving implicitly a system where the inverse matrix is known to be dense, is to not to calculate the dense matrix at all!!** The inverse problem, in fact, can be solved using a sparse solver. In this specific case, instead of calculating the inverse of $I+A$, the inverse problem $\\mathsf{(I+A)} \\cdot \\mathbf{T}^{t+\\Delta t} =  \\mathbf{T}^{t}$ is solved as such. This can be done as: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "IA = sparse.eye(nxp).tocsc()+tridiagSparse(r,nxp)\n",
    "B = (la.inv(IA)).todense()\n",
    "#print(r)\n",
    "#plt.imshow(IA.todense());plt.colorbar();plt.show()\n",
    "#plt.imshow(B);plt.colorbar();plt.show()\n",
    "#print(B.shape)\n",
    "t0=time.time()\n",
    "T = np.sin(2*np.pi*X)\n",
    "for thisStep in np.arange(steps):\n",
    "    T = la.spsolve(IA,T)\n",
    "print(time.time()-t0)\n",
    "plt.plot(T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "Remember that operators can be multiplied one for another. So, instead of calculating the evolution of the vector T from one step to the next, **steps** times, we can multiply the operator by itself **steps** times (or, if it is a constant operator, calculate the **steps** power of it) and then use the result to calculate the solution. Will it work? Do it as an exercise!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here write your solution\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach requires the same computing time of the dense approach for $nxp=1000$ but it then works also efficiently for greater problem sizes, while the dense matrix approach simply cannot be applied because the matrices reach computer size. \n",
    "\n",
    "### Exercise 6\n",
    "Do a scaling test if the three approaches and plot the time required to solve one timestep for different resolutions. For which problem size does the sparse solver become the best one? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here write your solution\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
